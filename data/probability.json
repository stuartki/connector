[{"title": "probability is greater than 0 for all events", "type": "axiom", "description": "P(A) >= 0 for all events A \n", "keywords": [""], "past": [], "future": [5, 8, 43], "id": 1, "related": [2, 3]}, {"title": "total probability = 1", "type": "axiom", "description": "total probability = 1 \n", "keywords": [""], "past": [], "future": [4, 5, 8, 43], "id": 2, "related": [1, 3]}, {"title": "summation of events = summation of probabilities (addition rule)", "type": "axiom", "description": "For every infinite sequence of disjoint events A1 ... An the P(union of all events) = sum of all probabilities of events\n", "keywords": [""], "past": [], "future": [4, 6, 7, 8, 9, 10, 48], "id": 3, "related": [1, 2]}, {"title": "complement of A", "type": "theorem", "description": "P(Ac) = 1 - P(A) \n", "keywords": ["complement"], "past": [2, 3], "future": [], "id": 4, "related": []}, {"title": "probability is between 0 and 1", "type": "Theorem 1.5.5", "description": "0 <= P(A) <= 1 \n", "keywords": ["probability", "between"], "past": [1, 2], "future": [131], "id": 5, "related": []}, {"title": "Pr(A) <= Pr(B) if A in B", "type": "Theorem 1.5.4", "description": "If A in B then Pr(A) <= Pr(B) \n", "keywords": [""], "past": [3], "future": [], "id": 6, "related": []}, {"title": "Pr(empty set) = 0", "type": "Theorem 1.5.1", "description": "Pr(empty set) = 0 \n", "keywords": [""], "past": [3], "future": [], "id": 7, "related": []}, {"title": "probability", "type": "definition", "description": "probability on a sample space S is a specification of numbers Pr(A) for all events that satisfy Axioms 1 2 and 3. \n", "keywords": [""], "past": [1, 2, 3], "future": [11, 12, 22, 28, 34, 37, 41, 44, 46, 52, 53, 90, 134], "id": 8, "related": []}, {"title": "Pr(A intersection Bc) = Pr(A) - Pr(A intersection B)", "type": "Theorem 1.5.6", "description": "for every two events A and B Pr(A intersection Bc) = Pr(A) - Pr(A intersection B) \n", "keywords": [""], "past": [3], "future": [10], "id": 9, "related": []}, {"title": "Pr(A union B) = Pr(A) + Pr(B) - Pr(A intersection B) ", "type": "Theorem 1.5.7", "description": "Pr(A union B) = Pr(A) + Pr(B) - Pr(A intersection B) \n", "keywords": [""], "past": [3, 9], "future": [], "id": 10, "related": []}, {"title": "Bonferroni inequality", "type": "Theorem", "description": "Bonferroni inequality is P(union Ai) <= sum of P(Ai) and P(intersection Ai) >= 1- sum(P(Aic) \n", "keywords": [""], "past": [8], "future": [], "id": 11, "related": []}, {"title": "simple sample space", "type": "definition", "description": "a finite sample space is where S is every outcome is equally likely \n", "keywords": [""], "past": [8], "future": [], "id": 12, "related": []}, {"title": "multiplication rule", "type": "definition", "description": "multiplication rule is if a job consists of k parts (k >= 2) and the ith part has ni possible outcomes regardless of what outcomes came before then the job can be done in n1 x n2 x ... x nk ways \n", "keywords": [""], "past": [], "future": [14, 15, 16, 17], "id": 13, "related": []}, {"title": "ordered samples without replacement", "type": "definition", "description": "ordered samples without replacement is n", "keywords": [""], "past": [13], "future": [], "id": 14, "related": [15, 16, 17]}, {"title": "unordered samples without replacement", "type": "definition", "description": "unordered samples without replacement is Cnk = (n k) = n", "keywords": [""], "past": [13], "future": [18, 20], "id": 15, "related": [14, 16, 17]}, {"title": "ordered samples with replacement", "type": "definition", "description": "ordered samples with replacement is just n^k \n", "keywords": [""], "past": [13], "future": [], "id": 16, "related": [14, 15, 17]}, {"title": "unordered samples with replacement", "type": "definition", "description": "unordered samples with replacement is (n+k-1 k) \n", "keywords": [""], "past": [13], "future": [], "id": 17, "related": [14, 15, 16]}, {"title": "binomial coefficient", "type": "definition", "description": "binomial coefficient is the number of ways to choose k items out of n without replacement. (n k) = n", "keywords": [""], "past": [15], "future": [19, 39], "id": 18, "related": [20, 21]}, {"title": "binomial theorem", "type": "definition", "description": "binomial theorem is (x+y)^n = sum[n k](n k)x^k * y^(n-k) \n", "keywords": [""], "past": [18], "future": [39], "id": 19, "related": [20, 21]}, {"title": "multinomial coefficient", "type": "definition", "description": "multinomial coefficient is number of ways to divide n items into k different groups or (n n1...nk) = n", "keywords": [""], "past": [15], "future": [21], "id": 20, "related": [18, 19]}, {"title": "multinomial theorem", "type": "definition", "description": "multinomial theorem is (x1 + x2 + ... xk)^n = sum[n1...nk = n](n n1...nk)x1^n1 * x2^n2 * ... * xk^nk \n", "keywords": [""], "past": [20], "future": [], "id": 21, "related": [19, 18]}, {"title": "conditional probability", "type": "definition", "description": "conditional probability of event A given that event B has occured is P(A|B) = P(A intersection B)/P(B) if P(B) > 0 \n", "keywords": [""], "past": [8], "future": [23, 26, 27, 29, 61, 102], "id": 22, "related": []}, {"title": "the proportion of B that is also part of A", "type": "implication", "description": "Pr(A|B) is computed as the proportion of total probability Pr(B) that is represented by Pr(A intersection B). intuitively the proportion of B that is also part of A \n", "keywords": [""], "past": [22], "future": [], "id": 23, "related": []}, {"title": "partition", "type": "definition", "description": "partition is for S a sample space A1 ... Ak are disjoint and U[i infinity]Ai = S then the collection A1 A2 ... is called the partition of S \n", "keywords": [""], "past": [25], "future": [26, 27], "id": 24, "related": []}, {"title": "sample space S", "type": "definition", "description": "sample space S \n", "keywords": [""], "past": [], "future": [24, 34], "id": 25, "related": []}, {"title": "law of total probability", "type": "Theorem 2.1.4", "description": "law of total probability states that if B1...Bk forma  partition of the sample space S and P(Bj) > 0 for all j then for every event A in S: P(A) = sum[j=1 k] P(Bj)P(A|Bj) \n", "keywords": [""], "past": [24, 22], "future": [27, 103], "id": 26, "related": []}, {"title": "Bayes' Theorem", "type": "Theorem 2.3.1", "description": "Bayes' Theorem states that if B1...Bk form a partition of S and P(Bj) > 0 for all j and P(A) > 0 then P(Bi|A) = P(Bi)P(A|Bi)/sum[j=1 k]P(Bj)P(A|Bj). The denomiator can also be written as P(A). The numerator is equal to P(Bi intersection A) \n", "keywords": [""], "past": [22, 24, 26], "future": [], "id": 27, "related": []}, {"title": "independent events", "type": "definition", "description": "independence states that two events A and B are said to be statistically inindependent then P(A| intersection B) = P(A) * P(B) \n", "keywords": [""], "past": [8], "future": [29, 30, 31, 59], "id": 28, "related": []}, {"title": "conditional probabilities for independent events are just probabilities", "type": "implication", "description": "consequence of independence of A and B then P(A|B) = P(A intersection B)/P(B) = P(A)P(B)/P(B) = P(A). As well as P(B |A) = P(B) \n", "keywords": [""], "past": [22, 28], "future": [], "id": 29, "related": []}, {"title": "complements are independent", "type": "theorem", "description": "if A and B are independent then A and Bc or Ac and B or Ac and Bc are all indpependent as well \n", "keywords": [""], "past": [28], "future": [], "id": 30, "related": []}, {"title": "mutually independent events", "type": "definition", "description": "mutually independent events are when A1...Ak if for every subset Ai1 ... Aij j = 2...k then P(Ai1 intersection ... Aij) = P(Ai1) x ... x P(Aij) \n", "keywords": [""], "past": [28], "future": [32, 33], "id": 31, "related": []}, {"title": "mutual independence is not", "type": "implication", "description": "P(A inter B inter C) = P(A)P(B)P(C) does not imply mutual independence. Pairwise independence does not imply mutual independence \n", "keywords": [""], "past": [31], "future": [], "id": 32, "related": []}, {"title": "conditional independence", "type": "definition", "description": "conditional independence given B is for every subset Ai1...Aij of A1...Ak then P(Ai1 intersection ... Aij|B) = P(Ai1|B) x ... x P(Aij|B) \n", "keywords": [""], "past": [31], "future": [], "id": 33, "related": []}, {"title": "random variable", "type": "definition", "description": "random variable is a function from a sample space S to the real numbers R. P(X = xi) = P({sj in S: X(sj) = xi} where xi in A \n", "keywords": [""], "past": [25, 8], "future": [35, 36, 40, 51, 52, 53, 59, 61, 63, 66, 69, 70, 71, 86, 87, 109, 134], "id": 34, "related": []}, {"title": "support of random variable", "type": "definition", "description": "support of X is the range of X \n", "keywords": [""], "past": [34], "future": [], "id": 35, "related": []}, {"title": "discrete random variable", "type": "definition", "description": "random variable X is said to have a discrete distribution if X can only take countable number of different values \n", "keywords": [""], "past": [34], "future": [37, 110], "id": 36, "related": [40]}, {"title": "probability mass function", "type": "definition", "description": "probability mass function is defined as f(x) = P(X=x) defined for all x in R.  ", "keywords": [], "past": [8, 36], "future": [38, 39, 43, 44, 51, 53, 57, 60, 72, 73, 110, 112], "id": 37, "related": [41]}, {"title": "Bernoulli distribution with parameter p", "type": "definition", "description": "Bernoulli distribution with parameter p is X ~ Bernoulli(p) then the pmf is f(x) = p, if x=1 : 1-p, if x = 0 : 0, otherwise. X = 0 if loss and X = 1 if win ", "keywords": [], "past": [37], "future": [107, 109, 112, 113], "id": 38, "related": []}, {"title": "Binomial distribution with parameters n and p", "type": "definition", "description": "binomial distribution if X is number of successes in n independent trials where the probability of success is p. Then P(X=x) = (n k)p^x * (1-p)^(n-x) x = 0,1,...,n. X ~ Binomial(n,p) ", "keywords": [], "past": [37, 18, 19, 107], "future": [108, 110], "id": 39, "related": []}, {"title": "continuous random variables", "type": "definition", "description": "continuous random variables ", "keywords": [], "past": [34], "future": [41, 67, 68], "id": 40, "related": [36]}, {"title": "probability density function", "type": "definition", "description": "probability density function or pdf is a non-negative function from continuous random variable X where f defined on real line is P(x1 <= X <= x2) = int[x1,x2]f(x)dx ", "keywords": [], "past": [40, 8], "future": [42, 43, 44, 51, 53, 55, 57, 60, 66, 68, 69, 70, 71, 72, 73, 82], "id": 41, "related": [37]}, {"title": "uniform distribution", "type": "definition", "description": "uniform distribution is f(x) = 1/(b-a) for x in [a,b]. X~Uniform(a,b) ", "keywords": [], "past": [41], "future": [67, 130], "id": 42, "related": []}, {"title": "probability density function has f(x)>=0 and sum of all = 1", "type": "theorem", "description": "a pdf of a random variable holds iff both f(x) >= 0 and sum(1 infinity)[f(xi)] = 1 and int(-inf inf)[f(x)dx] = 1  ", "keywords": [], "past": [41, 37, 2, 1], "future": [], "id": 43, "related": []}, {"title": "cumulative distribution function", "type": "definition", "description": "cumulative distribution function is F(x) = P(X<=x) for all x ", "keywords": [], "past": [8, 41, 37], "future": [45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 58, 67, 128], "id": 44, "related": []}, {"title": "F(x) = int(-inf x)[f(u)du or F(xi) = sum(u<=xi)[f(u)]", "type": "definition", "description": "F(x) = int(-inf x)[f(u)du or F(xi) = sum(u<=xi)[f(u)] ", "keywords": [], "past": [44], "future": [56, 57], "id": 45, "related": []}, {"title": "function is a cdf if the following hold", "type": "theorem", "description": "a function F(x) is a cdf iff lim(x->inf)F(x) = 0 and lim(x->-inf)F(x) = 1, F(x) is a nondecreasing function of x, F(x) is right-continuous; lim(x->x0)F(x) = F(x0) ", "keywords": [], "past": [44, 8], "future": [], "id": 46, "related": []}, {"title": "Pr(X>x) = 1-F(x)", "type": "Theorem 3.3.1", "description": "for every value x Pr(X>x) = 1-F(x) ", "keywords": [], "past": [44], "future": [], "id": 47, "related": []}, {"title": "Pr(x1 < X <= x2) = F(x2) - F(x1)", "type": "Theorem 3.3.2", "description": "Pr(x1 < X <= x2) = F(x2) - F(x1) ", "keywords": [], "past": [3, 44], "future": [], "id": 48, "related": []}, {"title": "Pr(X<x) = F(x-)", "type": "Theorem 3.3.3", "description": "Pr(X<x) = F(x-) ", "keywords": [], "past": [44], "future": [50], "id": 49, "related": []}, {"title": "Pr(X = x) = F(x) - F(x-)", "type": "Theorem 3.3.4", "description": "Pr(X = x) = F(x) - F(x-) ", "keywords": [], "past": [49, 44], "future": [], "id": 50, "related": []}, {"title": "identically distributed", "type": "definition", "description": "identically distributed if for every set A we have P(X in A) = P(Y in A) for random variables X and Y ", "keywords": [], "past": [34, 37, 41, 44], "future": [], "id": 51, "related": []}, {"title": "quantile function", "type": "definition", "description": "quantile function is with X random variable and cdf F(x) and let p in (0,1): F-1(p) = the smallest x such that F(x) >= p. if continuous and one-to-one then  there is only one x such that F(x) = p ", "keywords": [], "past": [34, 44, 8], "future": [67], "id": 52, "related": []}, {"title": "joint distribution", "type": "definition", "description": "the joint distribution or bivariate distribution of X and Y is the collection of all probabilities of the form Pr[(X,Y) in C] for all sets C of pairs of real numbers such that {(X,Y) in C} is an event ", "keywords": [], "past": [8, 37, 41, 34], "future": [54, 56, 57, 61, 91], "id": 53, "related": []}, {"title": "joint cumulative distribution", "type": "definition", "description": "joint cumulative distribution function of two random variables is F(x,y) = P(X<=x, Y<=y) for all x, y in X, Y ", "keywords": [], "past": [53, 44], "future": [56, 58], "id": 54, "related": []}, {"title": "dF(x)/dx = p(x)", "type": "definition", "description": "dF(x)/dx = p(x) ", "keywords": [], "past": [44, 41], "future": [56], "id": 55, "related": []}, {"title": "F(x,y) = d2F(x,y)/dxdy", "type": "definition", "description": "F(x,y) = d2F(x,y)/dxdy ", "keywords": [], "past": [55, 54, 53, 45], "future": [], "id": 56, "related": []}, {"title": "marginal distribution", "type": "definition", "description": "marginal pdfs are fx(x) = P(X = x) = sum/int[f(x,y)] over all y. similarly for fy(y) = sum over all x in joint distribution ", "keywords": [], "past": [53, 41, 37, 45], "future": [58, 60, 61, 62], "id": 57, "related": []}, {"title": "marginal cumulative distribution", "type": "definition", "description": "marginal cdf is the lim(y->inf)F(x,y) = Fx(x). similarly for Fy(y) ", "keywords": [], "past": [54, 44, 57], "future": [], "id": 58, "related": []}, {"title": "independent random variables", "type": "indepedence", "description": "independent random variables if for every two sets A and B in R the events {s: X(s) in A} and {s: Y(s) in B} are independent ", "keywords": [], "past": [28, 34], "future": [60, 62, 72, 77, 96, 97], "id": 59, "related": []}, {"title": "marginal pdfs multiplied give joint distribution if independent", "type": "theorem", "description": "two random variables X and Y with joint pf/pdf f(x,y) and marginal pf's/pdf's fx(x) and fy(y) are independent iff f(x,y) = fx(x)fy(y) ", "keywords": [], "past": [59, 57, 37, 41], "future": [], "id": 60, "related": []}, {"title": "conditional probability distribution function", "type": "definition", "description": "f(x|y) = f(x,y)/fy(y) is called the conditional pf/pdf of X given Y = y ", "keywords": [], "past": [57, 53, 22, 34], "future": [62, 127], "id": 61, "related": []}, {"title": "conditional probability indicates independence", "type": "theorem", "description": "random variables X and Y are independent iff f(x|y) = fx(x) ", "keywords": [], "past": [57, 61, 59], "future": [], "id": 62, "related": []}, {"title": "transformation of random variable", "type": "definition", "description": "if X is a random variable then any function of X, g(X), is also a random variable ", "keywords": [], "past": [34], "future": [64, 67, 68, 70, 72, 74], "id": 63, "related": []}, {"title": "inverse mapping ", "type": "definition", "description": "inverse mapping is defined as g^-1(A) = {x in X:g(x) in A} ", "keywords": [], "past": [63], "future": [65, 67], "id": 64, "related": []}, {"title": "inverse mapping in terms of X", "type": "definition", "description": "we can write P(Y in A) = P(g(X) in A) = P({x in X:g(x) in A}) = P(X in g-1(A)) ", "keywords": [], "past": [64], "future": [], "id": 65, "related": []}, {"title": "exponential distribution X ~ Exp(l)", "type": "distribution", "description": "exponential distribution X ~ Exp(l) = lexp(-lx), x > 0 ", "keywords": [], "past": [34, 41], "future": [126, 127, 128], "id": 66, "related": []}, {"title": "probability integral transformation", "type": "Theorem 3.8.3", "description": "let X have continuous cdf F and let Y = F(X). Then F(X) ~ Uniform(0,1). if Y ~Uniform(0,1) and F is continuous cdf with quantile function F^-1 then X = F-1(Y) has cdf F ", "keywords": [], "past": [44, 40, 63, 42, 64, 52], "future": [], "id": 67, "related": []}, {"title": "monotone transformations of continuous random variable", "type": "theorem", "description": "let x be a random variable with pdf fx(x) and let Y = g(X) where g iis a monotone function. Suppose fx(x) is continuous on X and that g-1(y) has a continuous derivative on Y = {y:y=g(x), x in X}. Then the pdf of Y is fy(y) = fx(g-1(y))|d(g-1(y))/dy| for y in Y. ", "keywords": [], "past": [63, 40, 41], "future": [70], "id": 68, "related": []}, {"title": "Gamma distribution X ~ Gamma (n,b)", "type": "distribution", "description": "Gamma distribution X ~ Gamma(n, b) has pdf f(x) = 1/(n-1)!b^n * x^(n-1) * e^-x//b ", "keywords": [], "past": [41, 34, 124], "future": [125, 126], "id": 69, "related": []}, {"title": "linear transformation of random variable", "type": "corollary", "description": "Let X be a random variable with pdf fx(x) and let Y = aX + b, a does not equal 0. Then fy(y) = 1/|a| * f((y-b)/a). ", "keywords": [], "past": [68, 63, 41, 34], "future": [115], "id": 70, "related": []}, {"title": "Normal distribution X ~ Norm (u, sigma^2)", "type": "distribution", "description": "Normal distribution with parameters u and variance are have notation X ~ N(u, sigma^2). fx(x) = 1/(sigma)(2pi)^2 * exp(-(x-u)^2/2(sigma)^2) ", "keywords": [], "past": [34, 41, 73], "future": [115, 116, 117, 118, 119, 120, 121, 122], "id": 71, "related": []}, {"title": "convolution of independent random variables", "type": "definition", "description": "convolution is X1 and X2 be independent continuous random variables and let Y  = X1 + X2. The distribution of Y is g(y) = int(-inf, inf)[f1(y-t)f2(t)dt if X1 and X2 are independent ", "keywords": [], "past": [59, 63, 41, 37], "future": [], "id": 72, "related": []}, {"title": "expectation or mean", "type": "definition", "description": "expected value or mean is E(X) is int(-int, inf)[xf(x)dx] ", "keywords": [], "past": [37, 41, 80], "future": [71, 74, 75, 76, 77, 78, 83, 86, 91, 102, 103, 116, 132], "id": 73, "related": []}, {"title": "E[g(X)] = int(-inf, inf)[g(x)f(x)dx] expectation of g(X) a function of X", "type": "Theorem 4.1.1", "description": "E[g(X)] = int(-inf, inf)[g(x)f(x)dx] ", "keywords": [], "past": [73, 63], "future": [], "id": 74, "related": []}, {"title": "properties of expectation are linear", "type": "implication", "description": "properties of expectation are that it is linear. E(aX+b) = aE(X) + b and let E[sum(n)[Xi]] = sum(n)[E[Xi]], as well as products if independent. ", "keywords": [], "past": [73], "future": [77, 96], "id": 75, "related": []}, {"title": "variance", "type": "definition", "description": "variance is with finite mean u is Var(X) = E((X-u)^2) and sigma = (Var(X))^.5. E(X^2) - E(X)^2 = Var(X) ", "keywords": [], "past": [73, 81], "future": [77, 79, 85, 91, 92, 99, 101, 105, 106, 116], "id": 76, "related": []}, {"title": "properties of the variance", "type": "definition", "description": "properties of the variance include Var(X) >= 0, Var(X) = 0 iff X is a constant. Var(aX + b) = a^2Var(X). If X1,...,Xn are independent we have Var(sum(n)[Xi]) = sum(n)[Var(Xi)] ", "keywords": [], "past": [75, 73, 76, 59], "future": [101], "id": 77, "related": []}, {"title": "mean is a measure of location", "type": "implication", "description": "mean is a measure of location ", "keywords": [], "past": [73], "future": [], "id": 78, "related": []}, {"title": "variance is a measure of scale", "type": "implication", "description": "variance is a measure of scale ", "keywords": [], "past": [76], "future": [], "id": 79, "related": []}, {"title": "kth moment of X", "type": "definition", "description": "E(X^k) is called the kth moment of X ", "keywords": [], "past": [], "future": [73, 87], "id": 80, "related": []}, {"title": "kth central moment of X", "type": "definition", "description": "E(X) = u, then E((X-u)^k) is called the kth central moment of X ", "keywords": [], "past": [], "future": [76, 84, 85], "id": 81, "related": []}, {"title": "symmetric distribution", "type": "definition", "description": "symmetric distribution is symmetric with respect to point x0 if f(x0 + d) = ff - f(x0 - d) for all d ", "keywords": [], "past": [41], "future": [83, 84], "id": 82, "related": []}, {"title": "mean is the point of symmetry", "type": "implication", "description": "if the mean of a symmetric distribution exists, then it is the point of symmetry ", "keywords": [], "past": [82, 73], "future": [], "id": 83, "related": []}, {"title": "odd kth central moment = 0 for symmetric distributions", "type": "implication", "description": "if the distribution of X is symmetric, then wrt its mean u, then E((X-u)^k) = 0 for k odd ", "keywords": [], "past": [81, 82], "future": [], "id": 84, "related": []}, {"title": "skewness", "type": "definition", "description": "skewness is measured as E((X-u)^3)/sigma^3 ", "keywords": [], "past": [76, 81], "future": [], "id": 85, "related": []}, {"title": "moment generating function", "type": "definition", "description": "moment generating function is = E[e^(tX)] for all t in R ", "keywords": [], "past": [73, 34], "future": [87, 88, 89, 111, 115, 122], "id": 86, "related": []}, {"title": "nth moment of X is nth derivative of moment generating function", "type": "Theorem 4.4.2", "description": "Let X be a random variable whose moment generating function is finite for t in  an open interval around zero. Then the nth moment of X is finite, and E[X^n] = dn/dtn (m.g.f(t)) at t = 0.  ", "keywords": [], "past": [80, 86, 34], "future": [], "id": 87, "related": []}, {"title": "properties of the moment generating function", "type": "theorem", "description": "psi_aX+b(t) = e^bt * psi_X(at), and if independent, psi_y(t) = prod(n)[psi_i(t)] ", "keywords": [], "past": [86], "future": [115], "id": 88, "related": []}, {"title": "uniqueness of moment generating function", "type": "Theorem 4.4.5", "description": "uniqueness of m.g.f. is if m.g.f. are finite and psi_X(t) = psi_Y(t) for all values of t, then X and Y have the same distribution ", "keywords": [], "past": [86], "future": [111, 115], "id": 89, "related": []}, {"title": "median", "type": "definition", "description": "median is when P(X<=m) >= 0.5 and P(X>=m) >=0.5 for every number m = median ", "keywords": [], "past": [8], "future": [], "id": 90, "related": []}, {"title": "covariance", "type": "expectation", "description": "covariance is defined as Cov(X,Y) = E((X-ux)(Y-uy)). Cov(X,Y) = E(XY) - E(X)E(Y) ", "keywords": [], "past": [73, 76, 53], "future": [92, 93, 96, 99, 100, 101], "id": 91, "related": []}, {"title": "correlation", "type": "definition", "description": "correlation is defined as Cor(X,Y) = Cov(X,Y)/sigma_x)(sigma_y) ", "keywords": [], "past": [91, 76], "future": [94, 95, 98], "id": 92, "related": []}, {"title": "covariance is how much X and Y depend on each other linearly ", "type": ["definition"], "description": "covariance is how much X and Y depend on each other linearly ", "keywords": [], "past": [91], "future": [95, 98], "id": 93, "related": []}, {"title": "correlation is values between -1 <= p <= 1 by the Schwarz Inequality ", "type": ["definition"], "description": "correlation is values between -1 <= p <= 1 by the Schwarz Inequality ", "keywords": [], "past": [92], "future": [98], "id": 94, "related": []}, {"title": "correlation is independent of scale of X and Y ", "type": ["definition"], "description": "correlation is independent of scale of X and Y ", "keywords": [], "past": [93, 92], "future": [], "id": 95, "related": []}, {"title": "if X and Y are independent, Cov(X,Y) = 0 ", "type": ["definition"], "description": "if X and Y are independent, Cov(X,Y) = 0 ", "keywords": [], "past": [59, 75, 91], "future": [97], "id": 96, "related": []}, {"title": "the opposite is not true as two random variables can be uncorrelated without being independent ", "type": ["definition"], "description": "the opposite is not true as two random variables can be uncorrelated without being independent ", "keywords": [], "past": [96, 59], "future": [], "id": 97, "related": []}, {"title": "if Y is a linear function of X, then X and Y are perfectly correlated, p(X,Y) = +-1 ", "type": ["definition"], "description": "if Y is a linear function of X, then X and Y are perfectly correlated, p(X,Y) = +-1 ", "keywords": [], "past": [92, 94, 93], "future": [], "id": 98, "related": []}, {"title": "Cov(X,X) = Var(X) ", "type": ["definition"], "description": "Cov(X,X) = Var(X) ", "keywords": [], "past": [91, 76], "future": [], "id": 99, "related": []}, {"title": "Cov(aX+b, cY+d) = acCov(X,Y) ", "type": ["definition"], "description": "Cov(aX+b, cY+d) = acCov(X,Y) ", "keywords": [], "past": [91], "future": [], "id": 100, "related": []}, {"title": "Var(aX + bY + c) = a^2(Var(X) + b^2(Var(Y)) + 2abCov(X,Y) ", "type": ["definition"], "description": "Var(aX + bY + c) = a^2(Var(X) + b^2(Var(Y)) + 2abCov(X,Y) ", "keywords": [], "past": [77, 76, 91], "future": [], "id": 101, "related": []}, {"title": "conditional expectation", "type": ["definition"], "description": "the conditional expectation of Y given X = x, denoted E(Y|x) or E(Y|X=x), is the mean of the conditional distribution of Y given X = x. E(Y|x) = int(all inf)[yf(y|x)dy ", "keywords": [], "past": [73, 22], "future": [103, 104, 105, 106], "id": 102, "related": []}, {"title": "law of total probability for expectations is E(E(Y|X)) = E(Y) ", "type": ["definition"], "description": "law of total probability for expectations is E(E(Y|X)) = E(Y) ", "keywords": [], "past": [102, 73, 26, 104], "future": [], "id": 103, "related": []}, {"title": "E(Y|X) is a random variable of E(Y|X = x) ", "type": ["definition"], "description": "E(Y|X) is a random variable of E(Y|X = x) ", "keywords": [], "past": [102], "future": [103], "id": 104, "related": []}, {"title": "conditional variance is E((Y-E(Y|x))^2|x) = Var(Y|x) ", "type": ["definition"], "description": "conditional variance is E((Y-E(Y|x))^2|x) = Var(Y|x) ", "keywords": [], "past": [102, 76], "future": [106], "id": 105, "related": []}, {"title": "law of total probability for variance is E[Var(Y|X)] + Var[E(Y|X)] = Var(Y) ", "type": ["definition"], "description": "law of total probability for variance is E[Var(Y|X)] + Var[E(Y|X)] = Var(Y) ", "keywords": [], "past": [102, 105, 76], "future": [], "id": 106, "related": []}, {"title": "sum of Bernoulli variables is Binomial distribution ", "type": ["definition", "implication"], "description": "sum of Bernoulli variables is Binomial distribution ", "keywords": [], "past": [38], "future": [39], "id": 107, "related": []}, {"title": "sum of Binomial variables B(n,p) is B(sum[n], p) ", "type": ["implication"], "description": "sum of Binomial variables B(n,p) is B(sum[n], p) ", "keywords": [], "past": [39], "future": [], "id": 108, "related": []}, {"title": "hypergeometric distribution", "type": ["distribution", "definition"], "description": "hypergeometric distribution is sampling without replacement with Bernoulli trials. This can be thought of a sum of dependent Bernoulli trials. see pf  ", "keywords": [], "past": [38, 34], "future": [], "id": 109, "related": []}, {"title": "Poisson distribution with parameter l", "type": ["distribution", "definition"], "description": "Poisson distribution is modeling consecutive arrivals for each interval of time, where the parameter l = np.  ", "keywords": [], "past": [39, 36, 37], "future": [111, 128], "id": 110, "related": []}, {"title": "sum of Poisson variables has Poisson distribution with mean sum[li] ", "type": ["implication"], "description": "sum of Poisson variables has Poisson distribution with mean sum[li] ", "keywords": [], "past": [89, 86, 110], "future": [], "id": 111, "related": []}, {"title": "Geometric distribution with parameter p", "type": ["definition", "distribution"], "description": "Geometric distribution is the number of failures before first success ", "keywords": [], "past": [38, 37], "future": [114], "id": 112, "related": []}, {"title": "Negative Binomial distribution with parameters r and p", "type": ["definition", "distribution"], "description": "Negative Binomial distribution with parameters r and p if it is the number of failures before the rth success ", "keywords": [], "past": [38, 114], "future": [], "id": 113, "related": []}, {"title": "sum of Geometric(p) variables is NegBinomial(r,p) ", "type": ["implication"], "description": "sum of Geometric(p) variables is NegBinomial(r,p) ", "keywords": [], "past": [112], "future": [113], "id": 114, "related": []}, {"title": "linear transformations of normal distributions are normal distributions ", "type": ["implication"], "description": "linear transformations of normal distributions are normal distributions ", "keywords": [], "past": [70, 89, 86, 71, 88], "future": [117, 118], "id": 115, "related": []}, {"title": "standard normal distribution has mean 0 and variance 1 ", "type": ["definition"], "description": "standard normal distribution has mean 0 and variance 1 ", "keywords": [], "past": [71, 73, 76], "future": [117], "id": 116, "related": []}, {"title": "F(x) = cdf of norm(x-u/sigma) ", "type": ["definition"], "description": "F(x) = cdf of norm(x-u/sigma) ", "keywords": [], "past": [116, 115, 71], "future": [], "id": 117, "related": []}, {"title": "linear combinations of normals are normal distributions ", "type": ["definition", "implication"], "description": "linear combinations of normals are normal distributions ", "keywords": [], "past": [115, 71], "future": [120], "id": 118, "related": []}, {"title": "sample mean", "type": ["definition"], "description": "sample mean is 1/n sum(n)[Xi] ", "keywords": [], "past": [71], "future": [120, 135], "id": 119, "related": []}, {"title": "sample mean is a normal distribution ", "type": ["definition"], "description": "sample mean is a normal distribution ", "keywords": [], "past": [71, 119, 118], "future": [135], "id": 120, "related": []}, {"title": "lognormal distribution", "type": ["definition"], "description": "lognormal distribution is log( X) = N(u, sigma^2) ", "keywords": [], "past": [71], "future": [], "id": 121, "related": []}, {"title": "moment generating function of lognormal is just E(X^t) ", "type": ["definition"], "description": "moment generating function of lognormal is just E(X^t) ", "keywords": [], "past": [86, 71], "future": [], "id": 122, "related": []}, {"title": "gamma function", "type": ["definition"], "description": "gamma function is g(a) = int[0,inf](x^(a-1)*e^-x) ", "keywords": [], "past": [], "future": [124, 129], "id": 123, "related": []}, {"title": "int[0,inf](x^(a-1)*e^-bx) = g(a)/b^a ", "type": ["definition"], "description": "int[0,inf](x^(a-1)*e^-bx) = g(a)/b^a ", "keywords": [], "past": [123], "future": [69, 125], "id": 124, "related": []}, {"title": "moments of the gamma function are g(a+k)/(b^k * g(a)) = E(X^k)", "type": ["definition"], "description": "moments of the gamma function are g(a+k)/(b^k * g(a)) = E(X^k) ", "keywords": [], "past": [69, 124], "future": [], "id": 125, "related": []}, {"title": "Gamma(1, b) is Expo(b)", "type": ["implication"], "description": "Gamma(1, b) is Expo(b) ", "keywords": [], "past": [66, 69], "future": [], "id": 126, "related": []}, {"title": "memoryless property of the exponential distribution", "type": ["implication"], "description": "Let X have the exponential distribution with parameter \u03b2, and let t > 0. Then for every number h>0, Pr(X>=t+h|X>=t) = Pr(X>=h) ", "keywords": [], "past": [66, 61], "future": [], "id": 127, "related": []}, {"title": "Times between arrivals in a Poisson process", "type": ["theorem"], "description": "Times between Arrivals in a Poisson Process. Suppose that arrivals occur according to a Poisson process with rate \u03b2. Let Zk be the time until the kth arrival for k = 1, 2, . . . . Define Y1 = Z1 and Yk = Zk \u2212 Zk\u22121 for k \u2265 2. Then Y1, Y2, . . . are i.i.d. and they each have the exponential distribution with parameter \u03b2. ", "keywords": [], "past": [110, 44, 66], "future": [], "id": 128, "related": []}, {"title": "Beta distribution with parameters a and b", "type": ["definition", "distribuiton", "distribution"], "description": "beta distribution with parameters a and b if it has pdf g(a+b)/g(a)g(b) * x^(a-1)(1-x)^(b-1) for 0 < x < 1 ", "keywords": [], "past": [123], "future": [130, 131], "id": 129, "related": []}, {"title": "Beta(1,1) = Uniform(0,1) ", "type": ["implication"], "description": "Beta(1,1) = Uniform(0,1) ", "keywords": [], "past": [42, 129], "future": [], "id": 130, "related": []}, {"title": "prior distributions for probability parameters the beta distribution ", "type": ["definition"], "description": "prior distributions for probability parameters the beta distribution ", "keywords": [], "past": [129, 5], "future": [], "id": 131, "related": []}, {"title": "markov's inequality ", "type": ["definition"], "description": "markov's inequality ", "keywords": [], "past": [73], "future": [133], "id": 132, "related": []}, {"title": "chebyshev inequality ", "type": ["definition"], "description": "chebyshev inequality ", "keywords": [], "past": [132], "future": [135], "id": 133, "related": []}, {"title": "convergence in probability", "type": ["definition"], "description": "convergence in probability is a sequence Z1,Z2,... of random variables converges to b in probability if for every number e > 0 lim[n->inf] Pr(|Zn-b|<e) = 1 ", "keywords": [], "past": [34, 8], "future": [135], "id": 134, "related": []}, {"title": "law of large numbers", "type": ["Theorem 6.2.4"], "description": "law of large numbers says for X1,...,Xn form a distribution for which the mean is u and variance is finite. sample mean will converge to u ", "keywords": [], "past": [133, 134, 120, 119], "future": [136], "id": 135, "related": []}, {"title": "normal distribution is easy for interpretation and analysis ", "type": ["implication"], "description": "normal distribution is easy for interpretation and analysis ", "keywords": [], "past": [135, 71], "future": [], "id": 136, "related": []}]